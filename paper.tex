\documentclass{article}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{cmap}
\usepackage[russian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{natbib}
\usepackage{amsmath}
\begin{document}
\begin{titlepage}

\begin{center}
Санкт-Петербургский Государственный Университет\\
Математико-механический факультет\\
\vspace{12em}
\textsc{\textbf{Курсовая работа\\}Сравнение алгоритмов классификации на предмет устойчивости к зашумлению входных данных}
\end{center}
\vspace{10em}
\begin{flushright}
Выполнил:\\
студент 243 группы\\
Владимир Назаренко\\
\vspace{1em}
Научный руководитель:\\
профессор Б.А. Новиков
\end{flushright}
\vspace{\fill}
\center
Санкт-Петербург\\2014
\end{titlepage}



\section{Введение}
Машинное обучение имеет множество применений в самых разных областях, например, в фильтрации спама \cite{spamFiltering}, или в построении некоторых заключений на основе показаний датчиков \cite{sensors}. Одной из возможностей также является анализ изображений.

Одним из методов машинного обучения является обучение по прецедентам.
Но качество работы алгорима, использующего этот метод, напрямую зависит от корректности и количества прецедентов(training set). К сожалению, информация о прецедентах зачастую содержит ошибки. Этой теме и посвящена данная работа -- исследуем устойчивость популярных алгоритмов машинного обучения по прецедентам к шумам в данных.



\section{Постановка задачи}
Чтобы как-то конкретизировать задачу, остановимся на рассмотрении алгоритмов классификации и выберем одни из наиболее популярных:
алгоритм на основе классифицирующего дерева(дерева выбора), байесовский классификатор и классификатор на основе метода опорных векторов. Выберем датасет и будем моделировать случайный шум на векторах признаков. Затем проведем два эксперимента: будем обучать классификатор на зашумленном тренировочном множестве и на незашумленном. Далее проверим качество работы классификатора на зашумленном тестовом множестве. Критерием качества будем считать процент верно классифицированных элементов в тестовом множестве. 


\section{Обзор предметной области}
\subsection{Классификация как задача машинного обучения}
Вообще говоря, основная терминология изложена, например, в статье Domingos \cite{fewUseful}, а описания алгоритмов в работе \cite{wu2008top}, но для удобства читателя я постараюсь разъяснить понятия, используемые далее в работе. 

Классификатор(алгоритм классификации) -- это система, которая принимает вектор дискретных и/или непрерывных величин -- вектор свойств объекта и выдаёт единственное дискретное значение - метку класса объекта. 

Пусть для множество объектов $X$, для которых нам известны вектора свойств и метки класса, тогда будем называть $X$ \emph{тренировочным множеством}. 

\subsection{Классификатор на основе дерева выбора}
\emph{Деревом выбора} будем называть дерево, каждому внутреннему узлу которого соответствует некая функция с конечным числом значений от свойства объекта, и каждому значению этой функции соответствует потомок узла. Каждому листовому узлу сопоставлена метка класса объекта. Коротко говоря, задачей алгоритма является построение оптимального дерева выбора. Затем достаточно было бы просто пройти по дереву, переходя в поддеревья, соответствующие свойствам объекта, и получить предполагаемую метку класса. Однако построение оптимального дерева является NP-полной задачей, поэтому приходится применять методы, развернуто описанные в работе~\cite{desicionTree}.
\subsection{Байесовский классификатор}
Пусть $x$ - вектор свойств, $y$ - метка класса. \\
Рассмотрим так называемый наивный Байесовский классификатор, так как другие байесовские классификаторы являются его улучшениями. В основе метода лежат две вещи:
\begin{itemize}
\item{теорема Байеса}

\begin{equation}
P(y=C|x)=\frac{P(C) P(x|y=C)}{P(x)}
,\hspace{5mm} x = (x_1, ..., x_n)
\end{equation}

\item{Предположение о том, что координаты вектора $x$ меняются \\независимо(увы, это далеко не всегда истинно)}
\end{itemize}
Тогда

\begin{equation}
P(x|y=C) = \prod_{i=1}^n{P(x_i|y=C)}
\end{equation}

\begin{equation}
P(x) = \prod_{i=1}^n{P(x_i)}
\end{equation}

\begin{equation}
\label{eq:bayesCl}
P(y=C|x)=\frac{P(C) \prod_{i=1}^n{P(x_i|y=C)}}{\prod_{i=1}^n{P(x_i)}}
\end{equation}

Заметим, что правая часть формулы \eqref{eq:bayesCl} вычисляется приближенно из данных тренировочного множества.
Тогда задача сводится к нахождению
\begin{equation}
\max_{C \in \{C_1,..,C_n\}}P(y=C|x)
\end{equation}

Подробно модель баесовского классификатора и детали реализации рассмотрены в работе
\cite{murphy2006naive}.

\subsection{Классификатор на основе метода опорных\\ векторов}
Основная идея в том, что вектор свойств интерпретируется геометрически --  как точка в d-мерном пространстве. Тогда, если у нас есть только два класса, то нужно их разделить гиперплоскостью, которую можно задать функцией $f(x)$, где $x$ - вектор свойств объекта. Чтобы узнать метку класса объекта с вектором свойств $x_1$ достаточно посмотреть на знак $f(x_1)$. Если классов более двух, достаточно использовать метод ``один против всех''(one-vs.-all). Но, во-первых, встаёт вопрос существования разделяющей плоскости, а, во-вторых, выбора оптимальной плоскости. Эти вопросы рассмотрены в статье \cite{svm}.


 
\section{Работы в данной области}
Есть достаточно много связанных с выбранной темой статей. В статье \cite{glick2004enrichment} произведено исследование деградации качества работы алгоритма наивный байес на зашумленных данных. В работе \cite{Mannino2009743} произведено обширное исследование пяти алгоритмов(в том числе SMO) на качество работы при ассиметричном зашумлении атрибутов. Quinlan произвел схожее исследование алгоритма на основе дерева выбора(ID3) в своей работе \cite{QuinlanTrees}. Недостатком этих работ является отсутствие тестов на датасетах с большим вектором признаков, что имеет место, например, при классификации изображений.

\section{Описание эксперимента}
В качестве датасета был выбран MNIST Database\cite{quanpt:mnistlecun}, содержащий 60000 черно-белых изображений рукописных десятичных цифр в виде 784 байтов, каждый из которых описывает яркость пикселя. Далее на изображения наносится шум следующим образом - случайно выбирается $c * 784$ пикселей, где $c$ - процент испорченных пикселей, и каждый выбранный пиксель случайным образом либо становится белым, что соответствует значению 255, либо чёрным(0). Пример зашумления изображений показан на рис.~\ref{fig:noise}. Ввиду ограниченности ресурсов все рассчёты проводились на подмножестве датасета размером 15000 элементов, разделенном на тренировочное и тестовое множество в пропорции 2:1.

\begin{figure}[ht!b]
\centering
\begin{minipage}{.3\textwidth}
	\includegraphics[width=\textwidth]{graphics/digits-nr0.jpg}
	\captionsetup{justification=centering}
	\caption*{Изображения без\\ шума}
\end{minipage}
\begin{minipage}{.3\textwidth}
	\includegraphics[width=\textwidth]{graphics/digits-nr30.jpg}
	\captionsetup{justification=centering}
	\caption*{ 30\% пикселей\\ испорчены}
\end{minipage}
\begin{minipage}{.3\textwidth}
	\includegraphics[width=\textwidth]{graphics/digits-nr60.jpg}
	\captionsetup{justification=centering}
	\caption*{ 60\% пикселей\\ испорчены}
\end{minipage}
\caption{Пример зашумления изображений}
\label{fig:noise}
\end{figure}
Для эксперимента были использованы реализации выбраных алгоритмов в пакете анализа данных Weka: Random Tree, Naive Bayes, SMO.

Для Random Tree и Naive Bayes были использованы стандартные параметры, но классификатору SMO требуется значительное количество времени для тренировки, в сравнении с другими выбранными алгоритмами, так что было решено провести небольшое дополнительное исследование этого алгоритма на зависимость времени и качества его работы от параметра complexity. Было выбрано подмножество датасета MNIST размером 15000 элементов. Затем алгоритм SMO был запущен 10 раз для каждого значения параметра на датасете с уровнем шума от 0.0 до 0.9. Шум наносился указанным выше образом. Исследование производилось на компьютере, оснащенном процессором Intel Core i7 2.5GHz.
\begin{figure}[ht!]
\includegraphics[width=\textwidth]{graphics/c_param.pdf}
\captionsetup{justification=centering}
\caption{Зависимость качества и времени работы алгоритма SMO от параметра complexity}
\label{fig:SMO_qual}
\end{figure}
Как видно по рис.~\ref{fig:SMO_qual}, лучшие результаты алгоритм показывает при значении параметра complexity 0.001 - это значение и будем использовать. Также отметим, что временные характеристики работы SMO очень сильно зависят от количества шума в данных.


\newpage
\section{Результаты эксперимента}
График на рис.~\ref{fig:perf1} иллюстрирует зависимость качества работы алгоритма от количества испорченных пикселей. Легко видеть, что эффективность Desicion Tree быстро падает и уже при 10\% испорченных пикселей количество корректных результатов падает до 50\%.
По графику на рис.~\ref{fig:perf2} в свою очередь видно, что при тренировке на незашумленных данных уже эффективность Naive Bayes падает очень быстро.
\newpage
\begin{figure}[ht!]
\includegraphics[width=\textwidth]{graphics/Perf_noised.pdf}
\captionsetup{justification=centering}
\caption{Эффективность алгоритмов при построении модели на зашумленных данных}
\label{fig:perf1}
\end{figure}


\begin{figure}[ht!]
\includegraphics[width=\textwidth]{graphics/Perf_unnoised.pdf}
\captionsetup{justification=centering}
\caption{Эффективность алгоритмов при построении модели на незашумленных данных}
\label{fig:perf2}
\end{figure}
\clearpage


\section{Анализ результатов}
\par
По рис.~\ref{fig:perf1} видно, что Naive Bayes и SMO показывают примерно одинаковые результаты. Тем не менее наблюдается существенно более высокий процент верно классифицированных элементов алгоритмом при уровне шума меньше 0.4. Это можно объяснить, во-первых, тем, что параметр complexity был подобран оптимальным для данного датасета, а во-вторых, тем, что Naive Bayes использует достаточно простую гипотезу, так что, более продвинутый вероятностный классификатор показал бы более впечатляющие результаты, исследованием этого занимались McCalum \& Nigam \cite{Mccallum1998}. Но подбор оптимальных параметров и оптимальных улучшений алгоритма выходит за рамки данной работы.

Плохие результаты Random Tree на рис.~\ref{fig:perf1} скорее всего вызваны теми же причинами, что и у Naive Bayes, кроме того, проблемы могут быть вызваны переобучением, так как вектор признаков в выбранном датасете достаточно большой. Тем не менее, наклон кривой Random Tree на рис.~\ref{fig:perf1} говорит сам за себя -- характеристики работы алгоритма сильно падают с количеством шума.

Первое, что видно на рис.~\ref{fig:perf2}: Naive Bayes практически перестаёт работать уже при относительно небольшом уровне шума. И вот почему. Вспомним тождество:
\begin{equation}
\tag{\ref{eq:bayesCl}}
P(y=C|x)=\frac{P(C) \prod_{i=1}^n{P(x_i|y=C)}}{\prod_{i=1}^n{P(x_i)}}
\end{equation}
Правая его часть оценивается статистически из тренировочного множества. Но, когда тестовое и тренировочное множество зашумлены ассиметрично, эта статистическая оценка становится бесполезной.
 Отмечу, что схожие данные были получены авторами статьи \cite{glick2004enrichment}. 
 
 Также отметим, что на качество работы алгоритма SMO имел высокое качество работы в обоих случаях.


\section{Выводы}
В работе было произведено сравнение алгоритмов Naive Bayes, SMO и Random Tree на предмет устойчивости к зашумлению входных данных. 
\begin{itemize}
\item{Алгоритм Random Tree оказался неустойчив к шуму}
\item{Алгоритм Naive Bayes показал весьма хорошие результаты при обучении на зашумленном множестве и неудовлетворительные при обучении на незашумленном}
\item{Классификатор SMO лучшие результаты из представленных алгоритмов}
\end{itemize}
\clearpage
\bibliographystyle{unsrt}
\bibliography{references}{}
\end{document}
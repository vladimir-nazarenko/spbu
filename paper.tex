\documentclass{article}
\usepackage{graphicx}
\usepackage{caption}
%\usepackage{minipage}
\usepackage{cmap}
\usepackage[russian]{babel}
\usepackage[utf8]{inputenc}
%\usepackage{cite}
\usepackage{natbib}
\begin{document}
\begin{titlepage}

\begin{center}
Санкт-Петербургский Государственный Университет\\
Математико-механический факультет\\
\vspace{12em}
\textsc{\textbf{Курсовая работа\\}Сравнение алгоритмов классификации на предмет устойчивости к зашумлению входных данных}
\end{center}
\vspace{10em}
\begin{flushright}
Выполнил:\\
студент 243 группы\\
Владимир Назаренко\\
\vspace{1em}
Научный руководитель:\\
профессор Б.А. Новиков
\end{flushright}
\vspace{\fill}
\center
Санкт-Петербург\\2014
\end{titlepage}
\section{Введение}
Изобилие алгоритмов машинного обучения даёт определённый простор для выбора. К сожалению данные, предоставленные для обработки, зачастую содержат ошибки и неточности. Не секрет, что критериев такого сравнения можно придумать очень много, так почему бы не сравнить алгоритмы по устойчивости к порче входных данных? 
\section{Постановка задачи}
Так как алгоритмов машинного обучения слишком много, остановимся на рассмотрении алгоритмов классификации и выберем одни из наиболее популярных:
алгоритм на основе классифицирующего дерева, вероятностный классификатор и линейный классификатор. Выберем датасет и будем моделировать случайный шум на данных. Затем различными способами попытаемся классифицировать данные.
Далее сравним результаты работы выбранных алгоритмов и попытаемся выяснить причины различия в качестве работы алгоритмов. Критерием качества работы алгоритма будем считать процент верно классифицированных элементов в тестовом множестве.
\section{Обзор предметной области}
\subsection{Классификация как задача машинного обучения}
Предположим, у нас есть набор объектов(к примеру, звёзды), обладающий некоторыми свойствами(количество планет в системе, светимость и т.д.). Далее зададим на наших объектах категории(класс звезды: белый карлик, красный гигант и т.д.). Пусть для $m$ объектов нам известны конкретные значения всех свойств и категории, тогда будем называть эти объекты \emph{тренировочным множеством}. Далее пусть у нас есть выборка из $n$ объектов, с тем же набором свойств, более того, значения этих свойств нам известны, но неизвестны значения категорий. Тогда задачу определения категории вышеупомянутых $n$ объектов на основе данных тренировочного множества будем называть \emph{задачей классификации}.
\subsection{Алгоритм на основе дерева выбора}
\emph{Деревом выбора} будем называть дерево, каждому узлу которого соответствует некий логический предикат относительно свойств объекта, а каждому листовому узлу сопоставлена метка категории объекта. Коротко говоря, задачей алгоритма является построение оптимального дерева выбора. Затем достаточно было бы просто последовательно протестировать новый элемент, пройдя по дереву до листового узла, получив предполагаемую категорию, к которой этот элемент принадлежит, но построение оптимального дерева является NP-полной задачей, поэтому приходится применять методы, развернуто описанные в работе~\cite{desicionTree}.
\subsection{Вероятностный классификатор}
Задачей вероятностного классификатора является, используя входные данные, построить вероятностное распределение над категориями. Подробно модель вероятностного классификатора на примере Naive Bayes рассмотрена в работе~\cite{naiveBayes}.
\subsection{Линейный классификатор}
Основная идея в том, что свойства набор свойств объекта представляется как точка в d-мерном пространстве, есть вероятность, что точки будут расположены кластерами, каждый из которых представляет свою категорию, тогда можно предположить, что любой объект этой категории будет приблизительно попадать в этот кластер. Таким образом нам нужно разделить эти точки (d-1)-мерными гиперплоскостями, а затем по новым данным об объекте проверять, в каком из кластеров находится точка, представляющая эти данные. Детально рассмотрена работа линейного классификатора на примере SVM в работе~\cite{svm}.

\section{Описание эксперимента}
В качестве датасета был выбран MNIST Database, содержащий изображения десятичных цифр, так как изображения в нём подвегнуты качественному перпроцессингу и мы можем быть уверены, что количество исходных шумов незначительно. Пример зашумления изображений показан на рис.1.

\begin{figure}[ht]
\centering
\begin{minipage}{.3\textwidth}
	\includegraphics[width=\textwidth]{graphics/digits-nr0.jpg}
	\captionsetup{justification=centering}
	\caption*{Изображения без\\ шума}
\end{minipage}
\begin{minipage}{.3\textwidth}
	\includegraphics[width=\textwidth]{graphics/digits-nr30.jpg}
	\captionsetup{justification=centering}
	\caption*{ 30\% пикселей\\ испорчены}
\end{minipage}
\begin{minipage}{.3\textwidth}
	\includegraphics[width=\textwidth]{graphics/digits-nr60.jpg}
	\captionsetup{justification=centering}
	\caption*{ 60\% пикселей\\ испорчены}
\end{minipage}
\caption{Пример зашумления изображений}
\end{figure}

В качестве конкретных реализаций выбранных алгоритмов используем Decision Tree classifier, Naive Bayes classifier и SMO classifier, реализованные в пакете анализа данных Weka.
\\Алгоритмы предполагается тестировать в двух ситуациях, так как они более всего вероятны в реальной ситуации и, следовательно, наиболее интересны:
\begin{itemize}
\item Модель строится на незашумленных данных, а проверяется на испорченных
\item Модель строися и проверяется на зашумленных данных
\end{itemize}
\section{Результаты эксперимента}
График на рис.2 иллюстрирует зависимость корректности работы алгоритма от количества испорченных пикселей. Легко видеть, что эффективность Desicion Tree быстро падает и уже при 10\% испорченных пикселей количество корректных результатов падает до 50\%.
По графику на рис.3 в свою очередь видно, что при тренировке на незашумленных данных уже эффективность Naive Bayes падает очень быстро.
\begin{figure}[ht]
\includegraphics[width=\textwidth]{graphics/Perf_noised.pdf}
\captionsetup{justification=centering}
\caption{Эффективность алгоритмов при построении модели на зашумленных данных}
\end{figure}
\begin{figure}[ht!]
\includegraphics[width=\textwidth]{graphics/Perf_unnoised.pdf}
\captionsetup{justification=centering}
\caption{Эффективность алгоритмов при построении модели на незашумленных данных}
\end{figure}

\section{Анализ результатов}
Видно, что лучше всех показал себя алгоритм SMO. Тем не менее обучение модели для него относительно ресурсоемко. Применимость двух других алгоритмов зависит от конкретной задачи, которую мы решаем.
\bibliographystyle{unsrt}
\bibliography{references}{}
\end{document}
\documentclass{article}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{cmap}
\usepackage[russian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{natbib}
\begin{document}
\begin{titlepage}

\begin{center}
Санкт-Петербургский Государственный Университет\\
Математико-механический факультет\\
\vspace{12em}
\textsc{\textbf{Курсовая работа\\}Сравнение алгоритмов классификации на предмет устойчивости к зашумлению входных данных}
\end{center}
\vspace{10em}
\begin{flushright}
Выполнил:\\
студент 243 группы\\
Владимир Назаренко\\
\vspace{1em}
Научный руководитель:\\
профессор Б.А. Новиков
\end{flushright}
\vspace{\fill}
\center
Санкт-Петербург\\2014
\end{titlepage}



\section{Введение}
Машинное обучение находит своё применение в самых разных областях, например, в фильтрации спама \cite{spamFiltering}, или в построении некоторых заключений на основе показаний датчиков \cite{sensors}. Одной из замечательных возможностей также является анализ изображений.

Изобилие алгоритмов машинного обучения даёт определённый простор для выбора, тем не менее, качество работы алгорима напрямую зависит от качества и количества входных данных. К сожалению данные, предоставленные для обработки, зачастую содержат ошибки и неточности. Этой теме и посвящена данная работа -- исследуем устойчивость популярных алгоритмов машинного обучения к зашумлению входных данных.



\section{Обзор предметной области}
\subsection{Классификация как задача машинного обучения}
Вообще говоря, основная терминология отлично изложена в статье Domingos \cite{fewUseful}, но для удобства читателя я постараюсь разъяснить понятия, используемые далее в работе.
Предположим, у нас есть набор объектов, обладающий некоторым вектором свойств. И пусть объекты можно разделить на классы на основе свойств. Пусть для $m$ объектов нам известны вектора свойств и метки класса, тогда будем называть эти объекты \emph{тренировочным множеством}. Далее пусть у нас есть выборка из $n$ объектов, с тем же набором свойств, более того, вектора свойств нам тоже известны, но неизвестны метки классов. Тогда задачу определения меток класса вышеупомянутых $n$ объектов на основе данных тренировочного множества будем называть \emph{задачей классификации} машинного обучения с учителем.
\subsection{Алгоритм на основе дерева выбора}
\emph{Деревом выбора} будем называть дерево, каждому узлу которого соответствует некий логический предикат относительно свойств объекта, а каждому листовому узлу сопоставлена метка категории объекта. Коротко говоря, задачей алгоритма является построение оптимального дерева выбора. Затем достаточно было бы просто последовательно протестировать новый элемент, пройдя по дереву до листового узла, получив предполагаемую категорию, к которой этот элемент принадлежит, но построение оптимального дерева является NP-полной задачей, поэтому приходится применять методы, развернуто описанные в работе~\cite{desicionTree}.
\subsection{Вероятностный классификатор}
Задачей вероятностного классификатора является, используя входные данные, построить вероятностное распределение над категориями. Подробно модель вероятностного классификатора на примере Naive Bayes рассмотрена в работе
\cite{murphy2006naive}.
\subsection{Линейный классификатор}
Основная идея в том, что свойства набор свойств объекта представляется как точка в d-мерном пространстве, есть вероятность, что точки будут расположены кластерами, каждый из которых представляет свою категорию, тогда можно предположить, что любой объект этой категории будет приблизительно попадать в этот кластер. Таким образом нам нужно разделить эти точки (d-1)-мерными гиперплоскостями, а затем по новым данным об объекте проверять, в каком из кластеров находится точка, представляющая эти данные. Детально рассмотрена работа линейного классификатора на примере SVM в работе~\cite{svm}.



\section{Постановка задачи}
Так как алгоритмов машинного обучения слишком много, остановимся на рассмотрении алгоритмов классификации и выберем одни из наиболее популярных:
алгоритм на основе классифицирующего дерева, вероятностный классификатор и линейный классификатор. Выберем датасет и будем моделировать случайный шум на тренировочном множестве. Затем различными алгоритмами попытаемся классифицировать данные. Критерием качества работы алгоритма будем считать процент верно классифицированных элементов в тестовом множестве. Кроме того, рассмотрены будут две ситуации: гипотеза строится на зашумленных данных и гипотеза строится на незашумленных данных.



\section{Работы в данной области}
К сожалению, найти статьи, в которых алгоритмы сравниваются приведенным выше образом мне не удалось. Но в статье \cite{glick2004enrichment} произведено похожее исследование алгоритма Naive Bayes. Ну и, вообще говоря, сравнение алгоритмов классификации по количеству верно классифицированных элементов производилось неоднократно \cite{Lorena20115268}\cite{Brown20123446}.


\section{Описание эксперимента}
В качестве датасета был выбран MNIST Database, содержащий 60000 черно-белых изображений рукописных десятичных цифр в виде 784 байтов, каждый из которых описывает яркость пикселя. Далее на изображения наносится шум следующим образом - случайным образом выбирается $c * 784$ пикселей, где $c$ - процент испорченных пикселей, и каждый выбранный пиксель случайным образом либо становится белым, что соответствует значению 255, либо чёрным. Пример зашумления изображений показан на рис.~\ref{fig:noise}. Ввиду ограниченности ресурсов все рассчёты проводились на подмножестве датасета размером 15000 элементов.

\begin{figure}[ht!b]
\centering
\begin{minipage}{.3\textwidth}
	\includegraphics[width=\textwidth]{graphics/digits-nr0.jpg}
	\captionsetup{justification=centering}
	\caption*{Изображения без\\ шума}
\end{minipage}
\begin{minipage}{.3\textwidth}
	\includegraphics[width=\textwidth]{graphics/digits-nr30.jpg}
	\captionsetup{justification=centering}
	\caption*{ 30\% пикселей\\ испорчены}
\end{minipage}
\begin{minipage}{.3\textwidth}
	\includegraphics[width=\textwidth]{graphics/digits-nr60.jpg}
	\captionsetup{justification=centering}
	\caption*{ 60\% пикселей\\ испорчены}
\end{minipage}
\caption{Пример зашумления изображений}
\label{fig:noise}
\end{figure}
В качестве конкретных реализаций выбранных алгоритмов используем Decision Tree classifier, Naive Bayes classifier и SMO classifier, реализованные в пакете анализа данных Weka.

Алгоритмы предполагается тестировать в двух ситуациях, так как они более всего вероятны в реальной ситуации и, следовательно, наиболее интересны:
\begin{itemize}
\item Модель строится на незашумленных данных, а проверяется на испорченных
\item Модель строися и проверяется на зашумленных данных
\end{itemize}

Кроме того, классификатору SMO требуется значительное количество времени для тренировки, в сравнении с другими выбранными алгоритмами, так что было решено провести небольшое дополнительное исследование этого алгоритма на зависимость времени и качества его работы от параметра алгоритма complexity. Было выбрано подмножество данных из датасета MNIST размером 15000. Данные последовательно зашумлялись описанным выше образом, а затем на девяти полученных датасетах со степенью зашумления от 0.0 до 0.9 был запущен алгоритм SMO с различными значениями исследуемого параметра. Исследование производилось на компьютере, оснащенном процессором Intel Core i7 2.5GHz.
\begin{figure}[ht]
\includegraphics[width=\textwidth]{graphics/c_param.pdf}
\captionsetup{justification=centering}
\caption{Зависимость качества и времени работы алгоритма SMO от параметра complexity}
\label{fig:SMO_qual}
\end{figure}
Как видно по рис.~\ref{fig:SMO_qual}, лучшие результаты алгоритм показывает при значении параметра complexity 0.001 - это значение и будем использовать. Также отметим, что временные характеристики работы SMO очень сильно зависят от количества шума в данных.


\newpage
\section{Результаты эксперимента}
График на рис.~\ref{fig:perf1} иллюстрирует зависимость корректности работы алгоритма от количества испорченных пикселей. Легко видеть, что эффективность Desicion Tree быстро падает и уже при 10\% испорченных пикселей количество корректных результатов падает до 50\%.
По графику на рис.~\ref{fig:perf2} в свою очередь видно, что при тренировке на незашумленных данных уже эффективность Naive Bayes падает очень быстро.
\begin{figure}[ht!]
\includegraphics[width=\textwidth]{graphics/Perf_noised.pdf}
\captionsetup{justification=centering}
\caption{Эффективность алгоритмов при построении модели на зашумленных данных}
\label{fig:perf1}
\end{figure}


\begin{figure}[ht!]
\includegraphics[width=\textwidth]{graphics/Perf_unnoised.pdf}
\captionsetup{justification=centering}
\caption{Эффективность алгоритмов при построении модели на незашумленных данных}
\label{fig:perf2}
\end{figure}
\clearpage


\section{Анализ результатов}
\par
По рис.~\ref{fig:perf1} видно, что Naive Bayes и SMO показывают примерно одинаковые результаты. Тем не менее наблюдается существенно более высокий процент верно классифицированных элементов алгоритмом при уровне шума меньше 0.4. Это можно объяснить, во-первых, тем, что параметр complexity был подобран оптимальным для данного датасета, а во-вторых, тем, что Naive Bayes использует достаточно простую гипотезу, так что, более продвинутый вероятностный классификатор показал бы более впечатляющие результаты, исследованием этого занимались McCalum \& Nigam \cite{Mccallum1998}. Но подбор оптимальных параметров и оптимальных улучшений алгоритма выходит за рамки данной работы.

Плохие результаты Random Tree на рис.~\ref{fig:perf1} скорее всего вызваны теми же причинами, что и у Naive Bayes, кроме того, проблемы могут быть вызваны переобучением, так как вектор признаков в выбранном датасете достаточно большой. Тем не менее, наклон кривой Random Tree на рис.~\ref{fig:perf1} говорит сам за себя -- характеристики работы алгоритма сильно падают с количеством шума.

Первое, что видно на рис.~\ref{fig:perf2}: Naive Bayes практически перестаёт работать уже при относительно небольшом уровне шума. Исследование причин такого поведения также выходит за рамки данной работы. Отмечу только, что схожие данные были получены авторами статьи \cite{glick2004enrichment}. Также отметим, что на корректность работы алгоритма SMO такой подход повлиял незначительно.


\section{Выводы}
В работе было произведено сравнение алгоритмов Naive Bayes, SMO и Random Tree на предмет устойчивости к зашумлению входных данных. 
\begin{itemize}
\item{Классификатор Random Tree оказался неустойчив к шуму.}
\item{Классификатор Naive Bayes показал весьма хорошие результаты при обучении на зашумленном множестве и неудовлетворительные при обучении на незашумленном.}
\item{Классификатор SMO отлично работал в обеих ситуациях}
\end{itemize}
\clearpage
\bibliographystyle{unsrt}
\bibliography{references}{}
\end{document}